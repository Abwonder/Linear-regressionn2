{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beee8890",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dea7da",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "What is R-squared?\n",
    "\n",
    "    A measure of how well a linear regression model fits the data\n",
    "\n",
    "     A measure of how well a logistic regression model fits the data\n",
    "\n",
    "    A measure of how well a decision tree model fits the data\n",
    "\n",
    "    A measure of how well a neural network model fits the data\n",
    "\n",
    "Explanation: R-squared, also known as the coefficient of determination, is a statistical measure that represents the proportion of variance in the dependent variable that is explained by the independent variable(s) in a linear regression model.\n",
    "\n",
    "2.\n",
    "\n",
    "What is the range of R-squared values?\n",
    "\n",
    "    0 to 1\n",
    "\n",
    "    -1 to 1\n",
    "\n",
    "    -∞ to ∞\n",
    "\n",
    "     None of the above\n",
    "\n",
    "Explanation: R-squared is a statistical measure that represents the proportion of variance in the dependent variable that is explained by the independent variable(s) in a linear regression model. It ranges from 0 to 1, with a higher value indicating a better fit.\n",
    "\n",
    "3.\n",
    "\n",
    "What is RMSE?\n",
    "\n",
    "    Root Mean Squared Error\n",
    "\n",
    "    Relative Mean Squared Error\n",
    "\n",
    "    Regularized Mean Squared Error\n",
    "\n",
    "    Random Mean Squared Error\n",
    "\n",
    "Explanation: RMSE is a measure of the differences between values predicted by a model and the actual values. It is calculated as the square root of the average squared difference between the predicted and actual values.\n",
    "\n",
    "4.\n",
    "\n",
    "What is the formula for RMSE?\n",
    "\n",
    "     √(Σ(y_pred - y_actual)^2 / n)\n",
    "\n",
    "     Σ(y_pred - y_actual)^2 / n\n",
    "\n",
    "    √Σ(y_pred - y_actual) / n\n",
    "\n",
    "     Σ(y_pred - y_actual) / n\n",
    "\n",
    "Explanation: RMSE is a measure of the differences between values predicted by a model and the actual values. It is calculated as the square root of the average squared difference between the predicted and actual values.\n",
    "\n",
    "5.\n",
    "\n",
    "What is the formula for MSE?\n",
    "\n",
    "    √(Σ(y_pred - y_actual)^2 / n)\n",
    "\n",
    "    Σ(y_pred - y_actual)^2 / n\n",
    "\n",
    "    √Σ(y_pred - y_actual) / n\n",
    "\n",
    "    Σ(y_pred - y_actual) / n\n",
    "\n",
    "Explanation: MSE is a measure of the differences between values predicted by a model and the actual values. It is calculated as the average squared difference between the predicted and actual values.\n",
    "\n",
    "6.\n",
    "\n",
    "Which type of regularization adds an L2 penalty term to the loss function?\n",
    "\n",
    "     Ridge Regression\n",
    "\n",
    "    Lasso Regression\n",
    "\n",
    "    Elastic Net\n",
    "\n",
    "    None of the above\n",
    "\n",
    "Explanation: Ridge Regression is a regularized linear regression model that adds an L2 penalty term to the loss function. The L2 penalty term adds a penalty proportional to the square of the magnitude of the coefficients. This penalty shrinks the coefficients towards zero, which helps to reduce overfitting and improve the generalization performance of the model. Ridge Regression is particularly useful when dealing with multicollinearity (high correlation) among the independent variables.\n",
    "\n",
    "7.\n",
    "\n",
    "Which type of regularization is most appropriate for a linear regression model with a large number of independent variables that are all potentially relevant?\n",
    "\n",
    "    Ridge Regression\n",
    "\n",
    "     Lasso Regression\n",
    "\n",
    "    Elastic Net\n",
    "\n",
    "    None of the above\n",
    "\n",
    "Explanation: Elastic Net is the most appropriate regularization method for a linear regression model with a large number of independent variables that are all potentially relevant. Elastic Net combines both L1 and L2 regularization, which allows it to handle situations where there are many independent variables and some of them are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8205521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
